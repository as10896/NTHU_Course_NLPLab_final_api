{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymagnitude import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import faiss\n",
    "import re\n",
    "from operator import itemgetter, attrgetter\n",
    "import json\n",
    "import time\n",
    "import aspell\n",
    "s = aspell.Speller('lang', 'en')\n",
    "vectors = Magnitude(\"glove.840B.300d.magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "def difflib_leven(str1, str2):\n",
    "    leven_cost = 0\n",
    "    s = difflib.SequenceMatcher(None, str1, str2)\n",
    "    for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "       #print('{:7} a[{}: {}] --> b[{}: {}] {} --> {}'.format(tag, i1, i2, j1, j2, str1[i1: i2], str2[j1: j2]))\n",
    "        if tag == 'replace':\n",
    "            leven_cost += max(i2-i1, j2-j1)\n",
    "        elif tag == 'insert':\n",
    "            leven_cost += (j2-j1)\n",
    "        elif tag == 'delete':\n",
    "            leven_cost += (i2-i1)\n",
    "    return leven_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_transform_eff = np.load('tran_vec.npy')\n",
    "emb = np.load(\"emb_vec.npy\")\n",
    "id2w = [i.strip() for i in open('id2w.txt', 'r').readlines()]\n",
    "with open('w2id.json') as f:\n",
    "    w2id = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196017 words now in index\n"
     ]
    }
   ],
   "source": [
    "d = emb.shape[1]                            # will be 300 - it's the number of dimensions of each word vector\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexFlatIP(d)                # This creates the index\n",
    "index.add(emb)                              # This adds all the word vectors to the index\n",
    "print(index.ntotal, 'words now in index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbours(word, transform_vector = spell_transform_eff, c=1.0, neighbours=1000,use_faiss=True):\n",
    "    \n",
    "    try:\n",
    "        word_embeds = np.vstack([emb[w2id[word]]])\n",
    "    except:\n",
    "        \n",
    "        word_embeds = np.vstack([vectors.query(word)])\n",
    "    \n",
    "    if use_faiss:\n",
    "        distances, indices = index.search(\n",
    "            (word_embeds - transform_vector*c).astype(np.float32), neighbours)\n",
    "    return indices\n",
    "\n",
    "def toWords(index_list):\n",
    "    res = []\n",
    "    for ind in index_list:\n",
    "        res.append([id2w[x].lower() for x in ind[:]])\n",
    "    result = [ x for r in res for x in sorted(set(r),key = r.index) if s.check(x) ] \n",
    "    return result\n",
    "\n",
    "def pick(candidates_list, mis_word , n , topn=1 , use_similarity = False):\n",
    "    p = []\n",
    "    not_found = True\n",
    "    for c in candidates_list:\n",
    "        #if difflib_leven(c,mis_word)<=3 and len(p)< n:\n",
    "        if difflib_leven(c,mis_word)<=3 and len(p)< n:\n",
    "            \n",
    "            if use_similarity:\n",
    "                sim = f_s.similarity( mis_word , c )\n",
    "                p.append((c,difflib_leven(c,mis_word),sim))\n",
    "            else:\n",
    "                p.append((c ,difflib_leven(c , mis_word)))\n",
    "                \n",
    "           \n",
    "            not_found = False\n",
    "            \n",
    "    if not_found:\n",
    "        p.append((mis_word,0,0))\n",
    "\n",
    "        \n",
    "    if use_similarity:\n",
    "        p = sorted(p,key=lambda x : (x[1],-x[2]))\n",
    "    else:\n",
    "        p = sorted(p , key=(lambda x:x[1]))\n",
    "        \n",
    "    #print(p)\n",
    "    p = [ pp[0] for pp in p ][:topn]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leaves', 'leave', 'leads', 'leafs', 'least']\n",
      "花費 :0.4025261402130127秒\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mispell = 'leavs '\n",
    "print(pick(toWords(getNeighbours(mispell,c=1.4)),mispell,50,5))\n",
    "end = time.time()\n",
    "print('花費 :' + str(end - start) + '秒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
